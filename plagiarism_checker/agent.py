"""
æ™ºèƒ½ Agent åˆ†ææ¨¡å—ï¼šä½¿ç”¨ LLM å¯¹é«˜é£é™©æ–‡æœ¬å¯¹è¿›è¡Œæ·±åº¦åˆ†æä¸è§£é‡Šã€‚
åŒ…æ‹¬è¯æ®é‡‡æ ·ã€ä¸Šä¸‹æ–‡æå–ã€æ§è¾©åŒæ–¹è§†è§’æ¨ç†ä¸ç»¼åˆåˆ¤å®šã€‚
æ”¯æŒ provider æŠ½è±¡ï¼ˆOpenAI æˆ–é€šç”¨ HTTPï¼‰ï¼Œé»˜è®¤å…¼å®¹ç°æœ‰é…ç½®ã€‚
"""

from __future__ import annotations
import json
import re
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass
import requests
from openai import OpenAI


@dataclass
class AgentAnalysis:
    """Agentåˆ†æç»“æœ"""
    is_plagiarism: bool
    confidence: float  # 0-1
    reasoning: str
    key_evidence: List[str]
    defense_points: List[str]


class SmartPlagiarismAgent:
    """
    æ™ºèƒ½æŠ„è¢­åˆ†æ Agentã€‚

    è¯»å– API é…ç½®ï¼Œåˆå§‹åŒ–å®¢æˆ·ç«¯ä¸æ¨¡å‹ï¼›æä¾›æ–¹å‘æ€§å¯¹çš„åˆ†æèƒ½åŠ›ã€‚
    """
    
    def __init__(self, api_config_path: str = "api_config.json", dual_phase: bool = True):
        """
        åˆå§‹åŒ– Agentã€‚

        Args:
            api_config_path: API é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œéœ€åŒ…å« base_url/api_key/modelã€‚
        """
        self.config = self._load_config(api_config_path)
        self.model = self.config.get('model')
        self.provider = self.config.get('provider', 'openai')
        self.dual_phase = dual_phase
        if self.provider == 'openai':
            self.client = OpenAI(
                base_url=self.config['base_url'],
                api_key=self.config['api_key']
            )
        else:
            self.client = None
    
    def _load_config(self, config_path: str) -> Dict:
        """
        åŠ è½½ API é…ç½®ã€‚

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ã€‚

        Returns:
            è§£æåçš„é…ç½®å­—å…¸ã€‚

        Raises:
            FileNotFoundError: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ã€‚
            KeyError: é…ç½®ä¸­ç¼ºå°‘å¿…é¡»å­—æ®µã€‚
        """
        config_path = Path(config_path)
        if not config_path.exists():
            raise FileNotFoundError(
                f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼è¯·åˆ›å»ºå¹¶å¡«å…¥API key"
            )
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # å…¼å®¹åŸæœ‰ 'modelscope' å­—æ®µï¼›ä¹Ÿæ”¯æŒ 'openai' æˆ–é€šç”¨ 'provider' å­—æ®µ
        if 'modelscope' in config:
            cfg = config['modelscope']
            cfg.setdefault('provider', 'openai')
            return cfg
        if 'openai' in config:
            cfg = config['openai']
            cfg['provider'] = 'openai'
            return cfg
        if 'provider' in config:
            return config
        raise KeyError("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘ 'modelscope'/'openai'/'provider' å­—æ®µ")
    
    def analyze_suspicious_pair(
        self,
        text_a: str,
        text_b: str,
        similarity_hits: List[Dict],
        statistics: Dict,
        left_name: str,
        right_name: str,
        dual_phase: bool = True
    ) -> AgentAnalysis:
        """
        åˆ†ææ–¹å‘æ€§æ–‡æœ¬å¯¹ï¼ˆå·¦=Targetï¼Œå³=Referenceï¼‰ï¼Œæ”¯æŒå•/åŒé˜¶æ®µè°ƒç”¨ã€‚
        ä¸­æ–‡æ³¨é‡Šï¼šç»Ÿä¸€ç»„ç»‡è¯æ®ä¸ç»Ÿè®¡ï¼Œå¹¶ä¼ é€’æ˜ç¡®çš„è§’è‰²åï¼Œé¿å… A/B æ··æ·†ã€‚
        """
        # æ™ºèƒ½é‡‡æ ·è¯æ®
        top_evidence = self._select_representative_evidence(similarity_hits, max_samples=5)
        
        # æå–ä¸Šä¸‹æ–‡
        evidence_contexts = self._extract_contexts(top_evidence)
        
        # æ£€å¯Ÿå®˜è§†è§’åˆ†æï¼ˆä¸­æ–‡æ³¨é‡Šï¼šåŠ å…¥ Target/Reference åç§°ï¼Œæé«˜å¯è¯»æ€§ï¼‰
        prosecutor_prompt = self._build_prosecutor_prompt(evidence_contexts, statistics, left_name, right_name)
        prosecutor_result = self._call_llm(prosecutor_prompt)
        defense_result = {'defense_points': []}
        if dual_phase and self.dual_phase:
            defense_prompt = self._build_defense_prompt(evidence_contexts, prosecutor_result)
            defense_result = self._call_llm(defense_prompt)
        
        # ç»¼åˆåˆ¤æ–­
        final_analysis = self._synthesize_judgment(
            prosecutor_result, 
            defense_result, 
            statistics
        )
        
        return final_analysis
    
    def _select_representative_evidence(
        self, 
        hits: List[Dict], 
        max_samples: int = 5
    ) -> List[Dict]:
        """
        æ™ºèƒ½é‡‡æ ·ï¼šä»å‘½ä¸­ä¸­é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„è¯æ®é›†åˆã€‚

        ç­–ç•¥ï¼šæœ€é«˜ç›¸ä¼¼åº¦ã€è‹¥å¹²ä¸­ç­‰ç›¸ä¼¼åº¦ã€ä½ç½®åˆ†æ•£çš„æ ·æœ¬ã€‚
        """
        if len(hits) <= max_samples:
            return hits
        
        sorted_hits = sorted(hits, key=lambda x: x['sim'], reverse=True)
        selected = []
        
        # æœ€é«˜ç›¸ä¼¼åº¦1å¯¹
        selected.append(sorted_hits[0])
        
        # ä¸­ç­‰ç›¸ä¼¼åº¦2å¯¹
        mid_start = len(sorted_hits) // 3
        mid_end = 2 * len(sorted_hits) // 3
        mid_range = sorted_hits[mid_start:mid_end]
        if len(mid_range) >= 2:
            step = len(mid_range) // 2
            selected.extend([mid_range[0], mid_range[step]])
        
        # ä½ç½®åˆ†æ•£2å¯¹
        remaining = [h for h in sorted_hits if h not in selected]
        if len(remaining) >= 2:
            positions = [h['sent_id_i'] for h in remaining]
            min_pos_idx = positions.index(min(positions))
            max_pos_idx = positions.index(max(positions))
            selected.extend([remaining[min_pos_idx], remaining[max_pos_idx]])
        
        return selected[:max_samples]
    
    def _extract_contexts(
        self,
        evidence: List[Dict]
    ) -> List[Dict]:
        """
        æå–è¯æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ–‡æœ¬ç‰‡æ®µã€ç›¸ä¼¼åº¦ã€ä½ç½®ã€æ˜¯å¦å«å¼•ç”¨ï¼‰ã€‚
        """
        contexts = []
        for hit in evidence:
            context = {
                'text_a': hit['text_i'],
                'text_b': hit['text_j'],
                'similarity': hit['sim'],
                'position_a': hit['sent_id_i'],
                'position_b': hit['sent_id_j'],
                'has_citation': hit.get('citation_penalty', 1.0) < 1.0
            }
            contexts.append(context)
        return contexts
    
    def _build_prosecutor_prompt(self, evidence: List[Dict], stats: Dict, left_name: str, right_name: str) -> str:
        """Build prosecutor perspective prompt (returns JSON). Clear Target/Reference names to avoid A/B confusion."""
        prompt = f"""You are an academic integrity prosecutor analyzing potential plagiarism.

**Statistical Data:**
- Similar sentences: {stats.get('count', 0)}
- Average similarity: {stats.get('mean_sim', 0):.1%}
- Maximum similarity: {stats.get('max_sim', 0):.1%}
- Text coverage: {stats.get('coverage_min', 0):.1%}

**Roles:**
- Target (under review): {left_name}
- Reference (source): {right_name}

**Key Evidence ({len(evidence)} pairs):**
"""
        
        for i, ctx in enumerate(evidence, 1):
            citation_mark = " [with citation]" if ctx['has_citation'] else ""
            prompt += f"""
Evidence {i} (similarity {ctx['similarity']:.1%}){citation_mark}
  Target({left_name}): "{ctx['text_a']}"
  Reference({right_name}): "{ctx['text_b']}"
"""
        
        prompt += """
**Please analyze (must return valid JSON):**
{
  "is_plagiarism": true,
  "confidence": 85,
  "reasoning": "Based on evidence...",
  "key_evidence": ["Evidence 1...", "Evidence 2..."],
  "evidence_assessments": [
    {"type":"verbatim","idx":1},
    {"type":"semantic","idx":2},
    {"type":"common_knowledge","idx":3},
    {"type":"quoted_with_citation","idx":4}
  ],
  "cross_lingual_mapping": true,
  "style_shift": false
}
Example:
{
  "is_plagiarism": false,
  "confidence": 60,
  "reasoning": "Sufficient citations and low coverage",
  "key_evidence": ["Evidence 1"],
  "evidence_assessments": [{"type":"common_knowledge","idx":1}],
  "cross_lingual_mapping": false,
  "style_shift": false
}
"""
        return prompt
    
    def _build_defense_prompt(self, evidence: List[Dict], prosecutor: Dict) -> str:
        """Build defense lawyer perspective prompt (requires JSON return)."""
        reasoning = prosecutor.get('reasoning', 'Unknown')
        
        prompt = f"""You are an academic defense attorney. The prosecution claims plagiarism with reasoning: {reasoning}

**Evidence:**
"""
        for i, ctx in enumerate(evidence, 1):
            citation = " [with citation]" if ctx['has_citation'] else ""
            prompt += f"{i}. Similarity {ctx['similarity']:.1%}{citation}\n"
        
        prompt += """
**Please provide defense (must return valid JSON):**
{
  "defense_points": ["Reason 1", "Reason 2"],
  "weakness": "The prosecution overlooked...",
  "alternative_explanation": "This could be..."
}
"""
        return prompt
    
    def _call_llm(self, prompt: str) -> Dict:
        """
        è°ƒç”¨ LLM API å¹¶è§£æï¼ˆå°½é‡æå– JSONï¼‰ã€‚

        Returns:
            Dict: è‹¥è§£ææˆåŠŸè¿”å›JSONå­—å…¸ï¼Œå¦åˆ™åŒ…å«åŸå§‹å“åº”æˆ–é”™è¯¯ä¿¡æ¯ã€‚
        """
        try:
            full_response = ""
            if self.provider == 'openai' and self.client is not None:
                # éæµå¼ï¼Œå¢å¼ºå…¼å®¹æ€§
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{'role': 'user', 'content': prompt}],
                    temperature=0.3
                )
                full_response = response.choices[0].message.content or ""
            else:
                # é€šç”¨ HTTP providerï¼šPOST åˆ° base_url
                base_url = self.config.get('base_url')
                api_key = self.config.get('api_key')
                headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}
                payload = {
                    'model': self.model,
                    'messages': [{'role': 'user', 'content': prompt}],
                    'temperature': 0.3
                }
                resp = requests.post(base_url, headers=headers, json=payload, timeout=30)
                resp.raise_for_status()
                data = resp.json()
                if 'choices' in data:
                    full_response = data['choices'][0]['message']['content']
                else:
                    full_response = json.dumps(data, ensure_ascii=False)

            json_match = re.search(r'\{.*\}', full_response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            return {'raw_response': full_response, 'parse_error': True}
        except Exception as e:
            return {'error': str(e), 'error_type': type(e).__name__}
    
    def _synthesize_judgment(
        self,
        prosecutor: Dict,
        defense: Dict,
        stats: Dict
    ) -> AgentAnalysis:
        """
        ç»¼åˆæ§è¾©åŒæ–¹è¾“å‡ºä¸ç»Ÿè®¡ï¼Œç”Ÿæˆæœ€ç»ˆåˆ¤å®šã€‚
        """
        if 'error' in prosecutor:
            return AgentAnalysis(
                is_plagiarism=False,
                confidence=0.0,
                reasoning=f"Analysis error: {prosecutor['error']}",
                key_evidence=[],
                defense_points=[]
            )
        
        is_plagiarism = prosecutor.get('is_plagiarism', False)
        confidence = prosecutor.get('confidence', 50) / 100.0
        
        # è¾©æŠ¤è°ƒæ•´
        defense_points = defense.get('defense_points', [])
        if defense_points:
            confidence_penalty = min(0.3, len(defense_points) * 0.1)
            confidence *= (1 - confidence_penalty)
        
        # ç»Ÿè®¡æ ¡å‡†
        coverage = stats.get('coverage_min', 0)
        mean_sim = stats.get('mean_sim', 0)
        if coverage > 0.8 and mean_sim > 0.9:
            confidence = min(0.95, confidence * 1.2)
        
        # å¼•ç”¨æ ¡å‡†
        avg_citation_penalty = stats.get('avg_citation_penalty', 1.0)
        if avg_citation_penalty < 0.5:
            confidence *= 0.7
            is_plagiarism = False
        
        return AgentAnalysis(
            is_plagiarism=is_plagiarism,
            confidence=confidence,
            reasoning=prosecutor.get('reasoning', ''),
            key_evidence=prosecutor.get('key_evidence', []),
            defense_points=defense_points
        )


def generate_agent_report(
    agent: SmartPlagiarismAgent,
    pair_detail: Dict,
    text_a: str,
    text_b: str,
    dual_phase: bool = True
) -> str:
    """
    ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šæ–‡æ¡ˆï¼ˆMarkdownï¼‰ã€‚
    """
    # ä¸­æ–‡æ³¨é‡Šï¼šä¼ å…¥æ˜ç¡®çš„æ–‡æ¡£åï¼Œé¿å… A/B æ··æ·†
    left_id = pair_detail['pair'][0]
    right_id = pair_detail['pair'][1]
    analysis = agent.analyze_suspicious_pair(
        text_a=text_a,
        text_b=text_b,
        similarity_hits=pair_detail['hits'],
        statistics={
            'count': pair_detail['count'],
            'mean_sim': pair_detail['mean_sim'],
            'max_sim': pair_detail['max_sim'],
            'coverage_min': pair_detail['coverage_min']
        },
        left_name=left_id,
        right_name=right_id,
        dual_phase=dual_phase
    )
    
    status_emoji = "âš ï¸" if analysis.is_plagiarism else "âœ…"
    status_text = "Potential plagiarism detected" if analysis.is_plagiarism else "No obvious plagiarism detected"
    
    report = f"""
## {status_emoji} AI Analysis Results

**Verdict**: {status_text}  
**Confidence**: {analysis.confidence:.1%}

### ğŸ¤” AI Reasoning Process
{analysis.reasoning}

### ğŸ“Œ Key Evidence
"""
    for i, evidence in enumerate(analysis.key_evidence, 1):
        report += f"{i}. {evidence}\n"
    
    if analysis.defense_points:
        report += "\n### ğŸ›¡ï¸ Possible Defense Arguments\n"
        for point in analysis.defense_points:
            report += f"- {point}\n"
    report += "\n### ğŸ§­ Semantic and Style Assessment\n- Cross-lingual semantic mapping: Please refer to reasoning above\n- Writing style variation: Please refer to reasoning above\n"
    # System-generated segment list (Top5) with clear Target/Reference and similarity scores.
    hits = pair_detail.get('hits', [])[:5]
    if hits:
        report += "\n### ğŸ“‘ Suspicious Segments (Top 5)\n"
        for i, h in enumerate(hits, 1):
            ta = h['text_i']
            tb = h['text_j']
            sim = h.get('adjusted_sim', h['sim'])
            report += f"{i}. Target({left_id}): \"{ta}\"\n   Reference({right_id}): \"{tb}\"\n   Similarity: {sim:.2f}\n"
    
    report += f"""
### ğŸ“Š Statistical Summary
- Similar sentences: {pair_detail['count']}
- Average similarity: {pair_detail['mean_sim']:.1%}
- Maximum similarity: {pair_detail['max_sim']:.1%}
- Text coverage: {pair_detail['coverage_min']:.1%}
"""
    
    return report

def generate_agent_report_batch(
    agent: SmartPlagiarismAgent,
    details: List[Dict],
    texts: Dict[str, str],
    dual_phase: bool = False
) -> List[Dict]:
    items = []
    for d in details:
        pair = d['pair']
        hits = d.get('hits', [])
        top_hits = sorted(hits, key=lambda x: x['sim'], reverse=True)[:5]
        evidence = []
        for h in top_hits:
            evidence.append({
                'text_a': h['text_i'][:160],
                'text_b': h['text_j'][:160],
                'similarity': h['sim'],
                'position_a': h['sent_id_i'],
                'position_b': h['sent_id_j'],
                'has_citation': h.get('citation_penalty', 1.0) < 1.0
            })
        items.append({
            'pair': pair,
            'stats': {
                'count': d['count'],
                'mean_sim': d['mean_sim'],
                'max_sim': d['max_sim'],
                'coverage_min': d['coverage_min']
            },
            'evidence': evidence,
            'full_a': texts.get(pair[0], '')[:8000],
            'full_b': texts.get(pair[1], '')[:8000]
        })
    prompt = "Batch analyze the following directional text pairs, return JSON list reports." + "\n"
    for it in items:
        prompt += f"PAIR Target({it['pair'][0]}) -> Reference({it['pair'][1]})\n"
        s = it['stats']
        prompt += f"count={s['count']}, mean={s['mean_sim']:.2f}, max={s['max_sim']:.2f}, coverage={s['coverage_min']:.2f}\n"
        prompt += f"FULL_A: {it['full_a']}\n"
        prompt += f"FULL_B: {it['full_b']}\n"
        for i, e in enumerate(it['evidence'], 1):
            mark = " [with citation]" if e['has_citation'] else ""
            prompt += f"E{i}{mark}: A=\"{e['text_a']}\" B=\"{e['text_b']}\" sim={e['similarity']:.2f}\n"
    prompt += "\nReturn in the following format:\n{" + "\n  \"reports\": [" + "\n    {\"pair\":[\"A\",\"B\"],\"is_plagiarism\":true,\"confidence\":0.85,\"reasoning\":\"...\",\"key_evidence\":[\"...\"],\"defense_points\":[\"...\"]}" + "\n  ]\n}"
    res = agent._call_llm(prompt)
    reports = []
    if isinstance(res, dict) and 'reports' in res:
        for r in res['reports']:
            pair = r.get('pair')
            md = f"## {'âš ï¸' if r.get('is_plagiarism') else 'âœ…'} AI Analysis Results\n\n"
            md += f"**Verdict**: {'Potential plagiarism detected' if r.get('is_plagiarism') else 'No obvious plagiarism detected'}  \n"
            md += f"**Confidence**: {float(r.get('confidence',0))*100:.1f}%\n\n"
            md += "### ğŸ¤” AI Reasoning Process\n" + str(r.get('reasoning','')) + "\n\n"
            md += "### ğŸ“Œ Key Evidence\n"
            for i, ev in enumerate(r.get('key_evidence', []), 1):
                md += f"{i}. {ev}\n"
            if r.get('defense_points'):
                md += "\n### ğŸ›¡ï¸ Possible Defense Arguments\n"
                for p in r['defense_points']:
                    md += f"- {p}\n"
            reports.append({'pair': pair, 'report': md})
        return reports
    fallback = []
    for d in details:
        a = texts.get(d['pair'][0], '')
        b = texts.get(d['pair'][1], '')
        fallback.append({'pair': d['pair'], 'report': generate_agent_report(agent, d, a, b, dual_phase=dual_phase)})
    return fallback
